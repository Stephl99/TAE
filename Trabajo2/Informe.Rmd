---
title: "Informee"
author: "Stephany Michell Lobo Laguado"
date: "30/7/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Integrantes

* Santiago Franco Valencia
* Isabela Lujan Jaramillo
* Ana María Sánchez Henao
* Daniel Alexander Naranjo Ríos
* Stephany Michell Lobo Laguado

```{r a, include=FALSE}
library(ggplot2)
library(gridExtra)
library(GGally)
library(Amelia)
library(reticulate)
library(knitr)
library(dplyr)
library(MASS)
library(caret)
library(caTools)
library(ggbiplot)
library(tidyverse)
library(naniar)
library(ggridges)
library(GGally)
library(viridis)
```

## Integrantes

* Santiago Franco Valencia
* Isabela Lujan Jaramillo
* Ana María Sánchez Henao
* Daniel Alexander Naranjo Ríos
* Stephany Michell Lobo Laguado

## Objetivo

El objetivo de este trabajo es llevar a cabo un ejercicio de segmentación de clientes para una base de datos simulada de una empresa cuyos clientes son otras empresas. Se pretende proponer por medio de técnicas de aprendizaje no superviado, una segmentación que permita a la empresa entender mejor a sus clientes, identificar patrones de uso de productos y canales y su relación con los estados financieros.

## Introducción

Debido a las distintas necesidades de los consumidores en el mundo actual, las empresas se han visto frente a la necesidad de dividir y clasificar a sus clientes en diversos grupos de acuerdo a características o deseos similares con el fin de optimizar sus procesos de promoción y comercialización de los distintos productos o servicios.

La segmentación de clientes surge como una estrategia que permite a las empresas optimizar de buena manera sus recursos al momento de ofrecer productos, teniendo en cuenta las necesidades específicas de los distintos consumidores. Una segmentación de clientes permite a las empresas enfocar adecuadamente sus esfuerzos de promoción de productos en pequeños grupos de clientes cuyas necesidades se ajusten a los servicios que la empresa ofrece. 

## Contextualización de los datos

El conjunto de datos utilizados es simulado, y está compuesto por dos distintos tipos de variables:

1. **De comportamiento de los clientes en los diferentes canales y productos de la empresa**

Hay hasta 10 distintos canales en los que se realizan acciones de entrada y salida. Estos se distinguen de acuerdo a las siguiente notación:

* en: entrada
* vm: valor medio anual
* tx: transacciones mensuales promedio
* sal: salida

- en_vm_canal...(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, otros)
- en_tx_canal...(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, otros)
- sal_vm_canal5...(5, 2, 8, otros)
- sal_tx_canal...(5, 2, 8, otros)

2. De estados financieros de los clientes

- impo_cv: [importaciones]/[compras] categorizadas
- expo_vt: [exportaciones]/[ventas] categorizadas
- cxp: [cuentas por pagar] categorizada con seis niveles
- cxc: [cuentas por cobrar] categorizada con seis niveles
- totalinventory: [valor de inventarios] categorizada con seis niveles
- pagos_pj: [pagos hechos a personas jurídicas]/[pagos totales]
- pagos_pn: [pagos hechos a personas naturales]/[pagos totales]
- tiene_ventas_fisicas: la empresa tiene puntos de venta físicos (1:Si, 0:No)
- tiene_ventas_electronicas: la empresa tiene ventas electrónicas (1:Si, 0:No)
- recaudos_pj: [recaudos provenientes de personas jurídicas]/[recaudos totales]
- recaudos_pn: [recaudos provenientes de personas naturales]/[recaudos totales]
- rotacion_inventarios: [rotación de inventarios en días] categorizada con seis niveles
- rotacion_cxc: [rotación de cuentas por pagar en días] categorizada con seis niveles
- rotacion_cxp: [rotación de cuentas por cobrar en días] categorizada con seis niveles
- ciclo_negocio: [ciclo de negocio en días] categorizada con seis niveles
- ciclo_financiero: [ciclo financiero en días] categorizada con seis niveles


## Funciones de Usuario

```{r}
conteo <- function(columna){
        ### Contar los na de una columna
  return(sum(is.na(columna)))
}

min_max <- function(columna){
        # Reescalado min/max
  columna <- (columna-min(columna))/(max(columna)-min(columna))
  return(columna)
}

crearTabla <- function(variable1, variable2){
        # Creación de tablas de contingencia
  tabla <- table(variable1, variable2)
  nueva_tabla <- as.data.frame(tabla)
  grafica <- ggplot(data = nueva_tabla, mapping = aes(x=variable1, y=variable2, fill=Freq)) + geom_tile()
  return(grafica + scale_fill_gradient2(low = "white",  high = "red"))
}
```

## Lectura de la base de datos

```{r}
base <- read.csv("base.csv", sep =";")
nits <- base$nit
base <- base[-1]
```

## Preprocesamiento de los datos

## Preprocesamiento variables númericas:

## Promedio de las respectivas transacciones en la base:

Se crean variables correspondientes al promedio de las transacciones diferentes en cada canal. Ya que cada entrada correspondiente a las transacciones representa la cantidad en promedio que se maneja de una transacción, se tiene que un 0 en la base de datos significa que no hubieron transacciones en ese respectivo canal. Por lo que se cálcula el promedio de las transacciones que fueron mayores a 0, y el valor de 0 indica que no se hizo ninguna transacción de la que se intenta promediar.

Se toma el nombre de las variables correspondientes a cada transacción:
```{r}
salientes_tx <- grepl("sal_tx", names(base))
salientes_vm <- grepl("sal_vm", names(base))
entrantes_tx <- grepl("en_tx", names(base))
entrantes_vm <- grepl("en_vm", names(base))
```

Se convierten los 0's a NA para poder aplicar un apply en las filas y se extrae la cantidad de NA's en cada fila para estudiar el uso de cada canal:
```{r}
base[1:30][base[1:30] == 0] <- NA
conteo_nas <- apply(FUN = conteo, base, MARGIN = 2)
```

Se crean variables nuevas que corresponden al promedio en cada transacción:
```{r}
promedio_salientes_tx <- apply(base[salientes_tx], MARGIN = 1, mean, na.rm = TRUE)
promedio_salientes_vm <- apply(base[salientes_vm], MARGIN = 1, mean, na.rm = TRUE)
promedio_entrantes_tx <- apply(base[entrantes_tx], MARGIN = 1, mean, na.rm = TRUE)
promedio_entrantes_vm <- apply(base[entrantes_vm], MARGIN = 1, mean, na.rm = TRUE)
```

Se crea un dataframe con las características encontradas en la base de datos:
```{r}
caracteristicas <- data.frame(promedio_entrantes_tx, promedio_salientes_vm,
                   promedio_salientes_tx, promedio_entrantes_vm)
caracteristicas[is.na(caracteristicas)] <-0
```

Ya que se tienen distancias muy grandes entre observaciones, una medida que puede hacer que las distancias entre las observaciones sea más robusta es la transformación logarítmica:

```{r}
caracteristicas <- log(caracteristicas + 1)
```

### 2. Rescalamiento Min-Max

Ahora, para obtener una medida más robusta usando un algoritmo de clustering como KNN se aplica rescaliento min/max en las variables:

```{r}
caracteristicas <- lapply(caracteristicas, min_max)
caracteristicas <- as.data.frame(caracteristicas)
kable(summary(caracteristicas[,1:4]))
```

### 3. Análisis de uso de los canales:

Ya que un valor de 0 en cada transacción significa que no hubieron transacciones en un canal, se analiza el comportamiento de las transacciones realizadas por cada empresa, para encontrar cuales son canales más o menos frecuentados:

```{r}
base[1:30][base[1:30]==0] <- NA
vis_miss(base[1:30], sort_miss = TRUE)

# Aqui los conteo_nas NA vuelven a ser cero
base[is.na(base)] <- 0
```
A partir de la gráfica se observa que existen canales en donde menos del 30% de las empresas realizan transacciones.

### 1. Transformación Logarítmica

```{r, fig.align='center', out.width='70%'}
mis.colores.3 <- colorRampPalette(c("#ff9999", "#99ff99", "#9999ff"))
a <- mis.colores.3(3)
par(mfrow=c(1,3))
hist(original$en_vm_canal1, col = a[1])
hist(original$en_vm_canal2, col = a[2])
hist(original$en_vm_canal3, col = a[3])
base <- log(base+1)
par(mfrow=c(1,3))
hist(base$en_vm_canal1, col = a[1])
hist(base$en_vm_canal2, col = a[2])
hist(base$en_vm_canal3, col = a[3])
```

### 2. Rescalamiento Min-Max

```{r}
base <- lapply(base, min_max)
base <- as.data.frame(base)
kable(summary(base[,1:4]))
```

### 3. Reemplazo de conteo_nas 0

```{r}
base[base==0] <- NA
```

### 4. Visualización de conteo_nas faltantes

Previamente se contaron la cantidad de transacciones ausentes por cada columna de la base, ordenando el vector resultante del conteo se obtiene el orden de las columnas respecto a la cantidad de valores ausentes que poseen y se realiza una gráfica de valores ausentes para observar cuantos NA'S hay en la base:

```{r}
base[1:30][base[1:30] == 0] <- NA
# Aqui los conteo_nas NA vuelven a ser cero (?)
vis_miss(base, sort_miss = TRUE)
base[is.na(base)] <- 0
```

En las variables poco usada se hizo un reemplazo de los conteo_nas que eran mayores a cero por el valor 1:

```{r}
# (?)
base[19:30][base[19:30] > 0] = 1
```

## Segmentación de la base de datos

### 1. Aplicación del algoritmo K vecinos más cercanos

Primero se necesita saber el número óptimo de vecinos, por medio de la gráfica de codos: 

```{r, fig.align='center', out.width='70%'}
set.seed(280721)
training <- base[1:18]
wcss <- vector()
for(i in 1:15){
  wcss[i] <- sum(kmeans(training, i)$withinss)
}
plot(wcss, type = "ol")
```


```{r, fig.align='center', out.width='70%}
set.seed(280721)
kmeans <- kmeans(training, 4, iter.max =1000, nstart = 10)
clusters <- kmeans$cluster
pca_training <- prcomp(base[1:18])
ggbiplot(pca_training, groups = factor(clusters ) )
```


```{r}
original[base == 0] <- NA
grupo1 <- original[which(clusters == 1), ]
grupo2 <- original[which(clusters == 2), ]
grupo3 <- original[which(clusters == 3), ]
grupo4 <- original[which(clusters == 4), ]

puntero <- original$en_vm_canal2
indices <- which( puntero < quantile(puntero, 0.95, na.rm = TRUE))
puntero <- puntero[indices] 
e <- ggplot(as.data.frame(puntero), aes(x=factor(clusters[indices]), y = puntero))
e + geom_boxplot()
```

Se observa que en cada grupo se presenta un comportamiento diferente entre cada canal.


# Aca falta el pedazo de codigo en donde la variable clusters se añade a base

```{r}
ggparcoord(base,
    columns = 1:14, groupColumn = 31
    ) +
   scale_color_viridis(discrete=F)+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```




```{r}
categoricos <- categoricos %>% mutate(cluster = base$clusters)
ggparcoord(categoricos,
    columns = 1:5, groupColumn = 17
    ) +
   scale_color_viridis(discrete=F)+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

